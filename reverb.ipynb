{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d44415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f77ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\", disable=[\"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d10a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = f\"\"\"Alphabet's Google might soon layoff nearly 6 per cent or 10,000 of its ‘poor performing' employees starting early 2023.\n",
    "According to a report by ‘The Information’ Google’s managers have been asked to analyse and rank the 'poor performing' employees. \n",
    "Alphabet currently employs around 1,87,000 employees. 10.0 of them are laid off.\n",
    "Google will use a ranking system and the lowest-ranked employees are expected to be fired from the company. \n",
    "Google had earlier announced that it will be slowing down the hiring process in the fourth quarter of the year. \n",
    "With this, Google will join other big tech companies, including Meta, Twitter, Amazon, etc, that have announced layoffs in the recent weeks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086396e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Amsterdam is the capital and largest city in the European country of the Netherlands.Amsterdam is famous for its canals and dikes. Unlike in capitals of most other countries, the national government, parliament, government ministries, supreme court, royal family and embassies are not in Amsterdam, but in The Hague. Located in the Dutch province of North Holland, Amsterdam is colloquially referred to as the 'Venice of the North'. The only diplomatic offices present in Amsterdam are consulates. The city hosts two universities (the University of Amsterdam and the Free University Amsterdam) and an international airport 'Schiphol Airport' built in 1923.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e2aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)\n",
    "sentences = [sentence for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3875aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [[\n",
    "#     {\"POS\": \"VERB\"},\n",
    "#     {\"TAG\": {\"IN\": [\"MD\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]}},\n",
    "    {\"DEP\": \"ROOT\"},\n",
    "    {\"POS\": \"PART\", \"OP\": \"?\"},\n",
    "    {\"POS\": \"ADV\",  \"OP\": \"?\"},\n",
    "    {\"POS\": {\"IN\": [\"PART\", \"ADP\"]}, \"OP\": \"?\"}\n",
    "]]\n",
    "\n",
    "pattern3 = [[\n",
    "    {\"POS\": \"VERB\"},\n",
    "    {\"POS\": \"PART\", \"OP\": \"?\"},\n",
    "    {\"POS\": \"ADV\",  \"OP\": \"?\"},\n",
    "    {\"POS\": {\"IN\": [\"ADJ\", \"ADV\", \"NOUN\", \"PRON\", \"DET\"]}, \"OP\": \"*\"},\n",
    "    {\"POS\": {\"IN\": [\"PART\", \"ADP\"]}, \"OP\": \"?\"}    \n",
    "]]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"pattern3\", pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e079044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam is the capital and largest city in the European country of the Netherlands.\n",
      "\n",
      "[('Amsterdam', 'GPE'), ('European', 'NORP'), ('Netherlands', 'GPE')]\n",
      "Amsterdam is famous for its canals and dikes.\n",
      "\n",
      "[('Amsterdam', 'GPE')]\n",
      "Unlike in capitals of most other countries, the national government, parliament, government ministries, supreme court, royal family and embassies are not in Amsterdam, but in The Hague.\n",
      "\n",
      "[('Amsterdam', 'GPE'), ('The Hague', 'GPE')]\n",
      "Located in the Dutch province of North Holland, Amsterdam is colloquially referred to as the 'Venice of the North'.\n",
      "\n",
      "[('Dutch', 'NORP'), ('North Holland', 'GPE'), ('Amsterdam', 'GPE'), (\"the 'Venice of the North\", 'GPE')]\n",
      "The only diplomatic offices present in Amsterdam are consulates.\n",
      "\n",
      "[('Amsterdam', 'GPE')]\n",
      "The city hosts two universities (the University of Amsterdam and the Free University Amsterdam) and an international airport 'Schiphol Airport' built in 1923.\n",
      "\n",
      "[('two', 'CARDINAL'), ('the University of Amsterdam', 'ORG'), ('the Free University Amsterdam', 'ORG'), (\"'Schiphol Airport\", 'FAC'), ('1923', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    print(f'{sentence}\\n')\n",
    "    print([(e.text, e.label_) for e in sentence.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a3b41216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_relations(sentence):\n",
    "    spans = []\n",
    "    relations = []\n",
    "    matches = matcher(sentence)\n",
    "    spans = [sentence[start:end] for _, start, end in matches]\n",
    "    spans = spacy.util.filter_spans(spans)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0d8d8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pos = {\"PROPN\", \"NOUN\", \"NUM\"}\n",
    "\n",
    "def extract_relation(s):\n",
    "    relations = []\n",
    "    ss = sentence.start\n",
    "    \n",
    "    # Get all named entities that has at least one NOURN/PROPN\n",
    "    ents = [e for e in s.ents if {t.pos_ for t in s[e.start - ss: e.end - ss]} & ner_pos]\n",
    "        \n",
    "    # Stop if there are less than 2 named entities\n",
    "    if len(ents) < 2:\n",
    "        return relations\n",
    "    \n",
    "    # Extract all possible relations in the sentence\n",
    "    spans = get_relations(s)\n",
    "    \n",
    "    for span in spans:\n",
    "        rs = span.start\n",
    "        \n",
    "        left = []\n",
    "        right = []\n",
    "        for e in ents:\n",
    "            offset = e.start - rs\n",
    "            if offset < 0:\n",
    "                left.append((-offset, e))\n",
    "            else:\n",
    "                right.append((offset, e))\n",
    "        if len(left) and len(right):\n",
    "            sorted_left = [x for _, x in sorted(left)]\n",
    "            sorted_right = [x for _, x in sorted(right)]\n",
    "            e1, e2 = sorted_left[0], sorted_right[0]\n",
    "            relations.append((e1, span.text.lower(), e2))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a5dfc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Schiphol Airport, 'built in', 1923)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_relation(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "15051a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(sentence):\n",
    "    ts = [(t.text, t.pos_, t.tag_, t.dep_, t.lemma_) for t in sentence if t.pos_]\n",
    "    return pd.DataFrame(ts, columns=['text', 'pos', 'tag', 'dep', 'lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06da023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"pre-proc/warcs-20221210-141217.csv\"\n",
    "rows = []\n",
    "\n",
    "with open(filename, newline='') as file:\n",
    "    csv_reader = csv.reader(file, quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "    c = 0\n",
    "    for row in csv_reader:\n",
    "        document = nlp(row[-1])\n",
    "        sentences = [s for s in document.sents]\n",
    "        for sentence in sentences:\n",
    "            relations = extract_relation(sentence)\n",
    "            for e1, r, e2 in relations:\n",
    "                rows.append((row[0], sentence, f\"{e1}-{r}-{e2}\"))\n",
    "        if (c := c + 1) % 20 == 0:\n",
    "            print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "37e8dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'relation-{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "res_directory = \"relations\"\n",
    "\n",
    "with open(f\"{res_directory}/{filename}.csv\", 'w', newline='', encoding='UTF-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows([row for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d06e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = {'NOUN', \"PROPN\", \"NUM\"}\n",
    "\n",
    "# s = sentences[3]\n",
    "# s_idx = s.start\n",
    "# ents = s.ents\n",
    "# spans, relations = get_relations(s)\n",
    "\n",
    "# span1 = spans[1]\n",
    "# span2 = spans[3]\n",
    "\n",
    "# span = span1\n",
    "\n",
    "# # Get entities that are noun / proper noun / or number\n",
    "# ents = [ent for ent in ents \n",
    "#         if {t.pos_ for t in s[ent.start - s_idx : ent.end - s_idx]} & pos]\n",
    "\n",
    "# # assert sure there are at least 2 entities left\n",
    "# assert len(ents) >= 2\n",
    "\n",
    "# # Get two entities closest to the relatioin (?? how about A, B relation C)\n",
    "# offsets = [abs(ent.start - span.start) for ent in ents]\n",
    "# sorted_ents = [x for _, x in sorted(zip(offsets, ents))]\n",
    "# e1, e2 = sorted_ents[0], sorted_ents[1]\n",
    "# print(e1, e2)\n",
    "\n",
    "# # Check if one sided and comma between entities\n",
    "# if (e1.start - span.start < 0) == (e2.start - span.start < 0) and any(t.text == ',' for t in s[e1.end-s.start:e2.start-s.start]):\n",
    "#     e1, e2 = e2, e1\n",
    "\n",
    "# print(f'{e1} - {span.text.lower()} - {e2}')\n",
    "\n",
    "# # get one closest entity from either side of the relation\n",
    "# left = []\n",
    "# right = []\n",
    "# for ent in ents:\n",
    "#     offset = ent.start - span.start\n",
    "#     if  offset < 0:\n",
    "#         left.append((-offset, ent))\n",
    "#     else:\n",
    "#         right.append((offset, ent))\n",
    "\n",
    "# sorted_left = [x for _, x in sorted(left)]\n",
    "# sorted_right = [x for _, x in sorted(right)]\n",
    "\n",
    "# e1, e2 = sorted_left[0], sorted_right[0]\n",
    "\n",
    "# print(f'{e1} - {span.text.lower()} - {e2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
